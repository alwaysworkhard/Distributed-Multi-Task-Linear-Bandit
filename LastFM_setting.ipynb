{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.lines as mlines\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import NMF\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "np.random.seed(3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artists = pd.read_csv('user_artists.dat', sep='\\t')\n",
    "\n",
    "artist_counts = user_artists['artistID'].value_counts()\n",
    "artists_filtered = artist_counts[artist_counts >= 30].index\n",
    "user_artists_filtered = user_artists[user_artists['artistID'].isin(artists_filtered)]\n",
    "\n",
    "user_counts = user_artists_filtered['userID'].value_counts()\n",
    "users_filtered = user_counts[user_counts >= 30].index\n",
    "user_artists_final = user_artists_filtered[user_artists_filtered['userID'].isin(users_filtered)]\n",
    "\n",
    "rating_matrix = pd.pivot_table(user_artists_final, index = 'userID', columns = 'artistID', aggfunc = lambda x: 1, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = 3\n",
    "d = d_ ** 2\n",
    "\n",
    "model = NMF(n_components = d_, init = 'nndsvda', max_iter = 10000)\n",
    "W = model.fit_transform(rating_matrix)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(W, H, d):\n",
    "    \n",
    "    phi_true = np.zeros((W.shape[0], H.shape[1], d))\n",
    "    psi_true = np.zeros((W.shape[0], H.shape[1], d))\n",
    "            \n",
    "    theta_true = np.eye(int(np.sqrt(d))).ravel()\n",
    "    theta_norm = np.linalg.norm(theta_true)\n",
    "    theta_true = theta_true / theta_norm\n",
    "    \n",
    "    for i in range(W.shape[0]):\n",
    "        \n",
    "        for j in range(H.shape[1]):\n",
    "            \n",
    "            temp = np.outer(W[i], H[:, j])\n",
    "            phi_true[i, j] = temp.ravel()\n",
    "            psi_true[i, j] = phi_true[i, j] + 1e-3 * np.random.normal(0, 1, d)\n",
    "            \n",
    "    max_value = np.max(np.dot(phi_true, theta_true))\n",
    "    phi_true = phi_true / max_value\n",
    "    psi_true = psi_true / max_value\n",
    "            \n",
    "    return phi_true, psi_true, theta_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_true, psi_true, theta_true = generate_data(W, H, d)\n",
    "phi_true.shape, psi_true.shape, theta_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the beta\n",
    "def get_beta(rho, delta, V_bar, theta_true):\n",
    "    \n",
    "    ld = 0.05\n",
    "    beta = rho * np.sqrt(2 * np.log((np.sqrt(np.linalg.det(V_bar)) * (np.linalg.det(ld * np.eye(d)) ** (-1/2))) / delta)) + np.sqrt(ld) * np.linalg.norm(theta_true)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc703a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slsqp\n",
    "def get_decision(psi_action, theta_hat, V_bar, beta, d):\n",
    "    \n",
    "    def maximize_reward(theta, psi_a):\n",
    "\n",
    "        return -1.0 * psi_a.dot(theta)\n",
    "    \n",
    "    # constraint confidence set: || theta_hat - theta ||_V_bar < Beta\n",
    "    def constraint(theta, theta_hat, V_bar, beta):\n",
    "        \n",
    "        temp = np.array(theta_hat - theta.reshape(-1, 1))\n",
    "        norm = np.sqrt(temp.reshape(-1, 1).T.dot(V_bar).dot(temp.reshape(-1, 1)))\n",
    "        \n",
    "        return beta - norm[0][0]\n",
    "    \n",
    "    # constraints for optimization\n",
    "    beta_constraint = {'type': 'ineq', 'fun' : lambda theta: constraint(theta, theta_hat, V_bar, beta)}\n",
    "    \n",
    "    theta_list = []\n",
    "    reward_list = []\n",
    "    \n",
    "    for psi_a in psi_action:\n",
    "        \n",
    "        res = minimize(maximize_reward, x0 = np.ones(d), args = (psi_a), method = 'SLSQP', constraints = [beta_constraint], options = {'ftol': 1e-3, 'eps': 1e-10, 'maxiter': 1e6, 'disp': False})\n",
    "        theta_list.append(res.x)\n",
    "        reward_list.append(psi_a.dot(res.x))\n",
    "        \n",
    "    decision = np.argmax(reward_list)\n",
    "    theta_tilde = theta_list[decision]\n",
    "    \n",
    "    return decision, theta_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0520379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_data(data_list, trials, iterations, num_agent, every_num_point):\n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    for T in range(trials):\n",
    "\n",
    "        new_list.append([item[1] for item in data_list if item[0] == T])\n",
    "\n",
    "    new_list = np.array(new_list).reshape(trials, iterations).tolist()\n",
    "    \n",
    "    data_value = np.zeros(iterations)\n",
    "    \n",
    "    for T in range(trials):\n",
    "        \n",
    "        data_value += np.array(new_list[T])\n",
    "        \n",
    "    data_value = data_value / trials\n",
    "    \n",
    "    x_value = [0]\n",
    "    y_value = [data_value[0] / num_agent[0]]\n",
    "    \n",
    "    for num in range(int(iterations / every_num_point)):\n",
    "        \n",
    "        x_value.append((num + 1) * every_num_point - 1)\n",
    "        y_value.append(data_value[(num + 1) * every_num_point - 1] / num_agent[0])\n",
    "    \n",
    "    return x_value, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 0.05\n",
    "ld = 0.05\n",
    "trials = 1\n",
    "alpha = 0.7\n",
    "num_agent = [1]\n",
    "baseline_idx = 5\n",
    "delta_value = 1e-2\n",
    "iterations = 10000000\n",
    "every_num_point = 25\n",
    "optimal_alg = []\n",
    "optimal_ECC = []\n",
    "optimal_sw = []\n",
    "optimal_sw_UCB = []\n",
    "reward_alg = []\n",
    "reward_ECC = []\n",
    "reward_sw = []\n",
    "reward_sw_UCB = []\n",
    "baseline_alg = []\n",
    "baseline_ECC = []\n",
    "baseline_sw = []\n",
    "baseline_sw_UCB = []\n",
    "cummulative_regret_alg = []\n",
    "cumulative_violate_alg = []\n",
    "cumulative_baseline_alg = []\n",
    "cummulative_regret_ECC = []\n",
    "cumulative_violate_ECC = []\n",
    "cumulative_baseline_ECC = []\n",
    "cummulative_regret_sw = []\n",
    "cumulative_violate_sw = []\n",
    "cumulative_baseline_sw = []\n",
    "cummulative_regret_sw_UCB = []\n",
    "cumulative_violate_sw_UCB = []\n",
    "cumulative_baseline_sw_UCB = []\n",
    "L = np.max(np.linalg.norm(phi_true, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bfa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_true_1 = phi_true.copy()\n",
    "phi_true_1[:, :, -1] = 0\n",
    "\n",
    "phi_true_2 = phi_true.copy()\n",
    "phi_true_2[:, :, 4] = 0\n",
    "\n",
    "phi_true_3 = phi_true.copy()\n",
    "phi_true_3[:, :, 0] = 0\n",
    "\n",
    "phi_true_group = np.array([phi_true, phi_true_1, phi_true_2, phi_true_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47439465",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_true_1 = psi_true.copy()\n",
    "psi_true_1[:, :, -1] = 0\n",
    "\n",
    "psi_true_2 = psi_true.copy()\n",
    "psi_true_2[:, :, 4] = 0\n",
    "\n",
    "psi_true_3 = psi_true.copy()\n",
    "psi_true_3[:, :, 0] = 0\n",
    "\n",
    "psi_true_group = np.array([psi_true, psi_true_1, psi_true_2, psi_true_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_group = np.array([phi_true_group[i].dot(theta_true) for i in range(np.shape(phi_true_group)[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae04785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the index set for context\n",
    "sample_id = np.random.randint(0, np.shape(phi_true)[0], size=(trials, iterations))\n",
    "\n",
    "# generate the noise of reward for each iteration\n",
    "noise = np.random.normal(0, 1e-3, size = (num_agent[-1], trials, iterations))\n",
    "\n",
    "# calculate r_l and r_h\n",
    "result_list = np.dot(phi_true_group[0], theta_true)\n",
    "sorted_list = np.sort(result_list, axis=1)\n",
    "selected_list = sorted_list[:, -baseline_idx]\n",
    "r_h = np.max(selected_list)\n",
    "r_l = np.min(selected_list)\n",
    "            \n",
    "# gererate rho_bar\n",
    "rho_bar = np.random.uniform(1e-10, alpha * r_l / (np.linalg.norm(theta_true) + r_h), size = (trials, iterations))\n",
    "\n",
    "# generate zeta\n",
    "zeta_data = np.random.normal(0, 1e-3, (trials, iterations, len(theta_true)))\n",
    "zeta_zero = zeta_data - np.mean(zeta_data, axis = 2, keepdims = True)\n",
    "zeta = zeta_zero / np.linalg.norm(zeta_zero, axis = 2, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our setting\n",
    "start = time.time()\n",
    "\n",
    "for M in num_agent:\n",
    "    \n",
    "    for T in range(trials):\n",
    "        \n",
    "        total_regret = 0\n",
    "        total_reward = 0\n",
    "        total_violate = 0\n",
    "        total_baseline = 0\n",
    "        cummulative_regret = []\n",
    "        cummulative_violate = []\n",
    "        cummulative_baseline = []\n",
    "        optimal_list = []\n",
    "        reward_list = []\n",
    "        baseline_list = []\n",
    "        \n",
    "        t_last = 0\n",
    "        V_last = ld * np.eye(d)\n",
    "        W_syn = np.zeros((d, d))\n",
    "        U_syn = np.zeros((d, 1))\n",
    "        \n",
    "        W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "        U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "        \n",
    "        B = (iterations * np.log(M * iterations)) / (d * M)\n",
    "        \n",
    "        syn = 0\n",
    "\n",
    "        for t in range(1, iterations + 1): \n",
    "            \n",
    "            index = sample_id[T][t-1]\n",
    "            \n",
    "            for i in range(M):\n",
    "                \n",
    "                phi = phi_true_group[i][index]\n",
    "                psi = psi_true_group[i][index]\n",
    "                original = rewards_group[i][index]\n",
    "\n",
    "                x_star = np.argmax(np.dot(np.array(psi), theta_true))\n",
    "                optimal = original[x_star]\n",
    "                \n",
    "                x_b = np.argsort(original)[::-1][baseline_idx]\n",
    "                r_b = original[x_b]\n",
    "                \n",
    "                V_bar = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                theta_hat = np.dot(np.linalg.inv(V_bar), (U_syn + U_new_list[i]))\n",
    "\n",
    "                # construct the confidence ellipsoid beta\n",
    "                beta = get_beta(rho = np.sqrt(1 + R ** 2), delta = delta_value / 2, V_bar = V_bar, theta_true = theta_true)\n",
    "                \n",
    "                #construct the trimmed action set\n",
    "                tas = (psi.dot(theta_hat) >= beta * L / np.sqrt(np.min(np.linalg.eigvals(V_bar))) + (1 - alpha) * r_b)\n",
    "                phi_set = phi[tas.ravel()]\n",
    "                psi_set = psi[tas.ravel()]\n",
    "                original_set = original[tas.ravel()]\n",
    "                \n",
    "                # get the best action\n",
    "                if (psi_set.size != 0) and (np.min(np.linalg.eigvals(V_bar)) >= np.square(2 * L * beta / (alpha * r_b))):\n",
    "                \n",
    "                    decision, theta_tilde = get_decision(psi_set, theta_hat, V_bar, beta, d)\n",
    "                    psi_new = psi_set[decision]\n",
    "                    y = original_set[decision]\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    decision = x_b\n",
    "                    total_baseline += 1\n",
    "                    psi_new = (1 - rho_bar[T][t-1]) * psi[decision] + rho_bar[T][t-1] * zeta[T][t-1]\n",
    "                    y = (1 - rho_bar[T][t-1]) * original[decision] + rho_bar[T][t-1] * np.dot(zeta[T][t-1], theta_true)\n",
    "                    \n",
    "                regret = optimal - y\n",
    "                total_regret = total_regret + regret\n",
    "                total_reward = total_reward + y\n",
    "\n",
    "                # update W_new and U_new\n",
    "                W_new_list[i] = W_new_list[i] + np.outer(psi_new, psi_new)\n",
    "                U_new_list[i] = U_new_list[i] + psi_new.reshape(-1, 1) * (y + noise[i][T][t-1])\n",
    "                V = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                \n",
    "                LHS_condition = np.log(np.linalg.det(V) / np.linalg.det(V_last)) * (t - t_last)\n",
    "                \n",
    "                if LHS_condition >= B:\n",
    "                    \n",
    "                    syn = 1\n",
    "                    \n",
    "                if y < (1 - alpha) * r_b:\n",
    "                    \n",
    "                    total_violate += 1\n",
    "                    \n",
    "            if syn == 1:\n",
    "                \n",
    "                W_syn = W_syn + np.sum(W_new_list, axis=0)\n",
    "                U_syn = U_syn + np.sum(U_new_list, axis=0)\n",
    "                \n",
    "                W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "                U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "                t_last = t\n",
    "                V_last = ld * np.eye(d) + W_syn\n",
    "                \n",
    "                syn = 0\n",
    "                \n",
    "            cummulative_regret.append(total_regret)\n",
    "            cummulative_violate.append(total_violate)\n",
    "            cummulative_baseline.append(total_baseline)\n",
    "            optimal_list.append(np.max(np.dot(phi, theta_true)))\n",
    "            reward_list.append(y)\n",
    "            baseline_list.append((1 - alpha) * r_b)\n",
    "            \n",
    "        cummulative_regret_alg.append((T, cummulative_regret))\n",
    "        cumulative_violate_alg.append((T, cummulative_violate))\n",
    "        cumulative_baseline_alg.append((T, cummulative_baseline))\n",
    "        optimal_alg.append((T, optimal_list))\n",
    "        reward_alg.append((T, reward_list))\n",
    "        baseline_alg.append((T, baseline_list))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value, y_alg = prepare_plot_data(cummulative_regret_alg, trials, iterations, num_agent, every_num_point)\n",
    "x_value_r, y_optimal_alg = prepare_plot_data(optimal_alg, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_reward_alg = prepare_plot_data(reward_alg, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_baseline_alg = prepare_plot_data(baseline_alg, trials, iterations, num_agent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "\n",
    "colors = (['black', 'blue', 'darkgreen', 'purple', 'darkred', 'grey'])\n",
    "markers = ['*', 's', 'o', 'X', '^', 'P']\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 25\n",
    "plt.rcParams['ytick.labelsize'] = 25\n",
    "plt.rc('legend', fontsize = 25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='both', scilimits=(0, 0), useOffset=False)\n",
    "\n",
    "plt.plot(x_value, y_alg, label = 'Algorithm', color = colors[1], linewidth=3)\n",
    "plt.scatter(x_value[::50000], y_alg[::50000], label = 'Algorithm', marker = markers[1], color = colors[1], s=300)\n",
    "\n",
    "legend_elements = [mlines.Line2D([0], [0], color=colors[1], lw = 5, label = 'DiSC-UCB', marker = markers[1], markersize = 15)]\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('round,t', fontsize=25)\n",
    "plt.ylabel('cumulative regret Rt', fontsize=25)\n",
    "plt.title('movielens data', fontsize=25)\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "plt.figure(figsize=(12,8), dpi=300)\n",
    "\n",
    "colors = (['black', 'blue', 'darkgreen', 'purple', 'darkred', 'grey'])\n",
    "markers = ['*', 's', 'o', 'X', '^', 'P']\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 25\n",
    "plt.rcParams['ytick.labelsize'] = 25\n",
    "plt.rc('legend', fontsize = 25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='both', scilimits=(0, 0), useOffset=False)\n",
    "\n",
    "plt.plot(x_value_r[::1000], y_optimal_alg[::1000], label = 'Optimal-Reward', linestyle = '--', color = colors[0], linewidth=3)\n",
    "plt.plot(x_value_r[::1000], y_reward_alg[::1000], label = 'DiSC-UCB', color = colors[1], linewidth=3)\n",
    "plt.plot(x_value_r[::1000], y_baseline_alg[::1000], label = 'Conservative-Reward', linestyle = '--', color = colors[5], linewidth=3)\n",
    "\n",
    "plt.ylim(0.0, 1.5)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('round,t', fontsize=25)\n",
    "plt.ylabel('reward,r', fontsize=25)\n",
    "plt.title('movielens data', fontsize=25)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe361e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
