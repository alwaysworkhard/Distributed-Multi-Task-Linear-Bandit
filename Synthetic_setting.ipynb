{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e048a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import NMF\n",
    "np.random.seed(9000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_context):\n",
    "    \n",
    "    d = 2\n",
    "    num_action = 40\n",
    "    \n",
    "    theta_true = np.array([0.9, 0.4])\n",
    "    \n",
    "    actions_per_group = num_action // 40\n",
    "    phi_true = np.zeros((num_context, num_action, d))\n",
    "\n",
    "    for i in range(num_context):\n",
    "        \n",
    "        for group in range(40):\n",
    "            \n",
    "            lower_bound = 0.975 - group * 0.025\n",
    "            upper_bound = 1.0 - group * 0.025\n",
    "            \n",
    "            for j in range(actions_per_group):\n",
    "                \n",
    "                while True:\n",
    "                    \n",
    "                    vec = np.random.randn(d)\n",
    "                    vec = vec / np.linalg.norm(vec)\n",
    "                    \n",
    "                    if lower_bound <= np.dot(vec, theta_true) <= upper_bound:\n",
    "                        \n",
    "                        phi_true[i][group * actions_per_group + j] = vec\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "    psi_true = np.zeros((num_context, num_action, d))\n",
    "    \n",
    "    for i in range(num_context):\n",
    "\n",
    "        for a in range(num_action):\n",
    "\n",
    "            psi_true[i, a] = phi_true[i, a] + np.random.normal(0, 2.5 * 1e-3, d)\n",
    "            \n",
    "    rewards = phi_true.dot(theta_true)\n",
    "\n",
    "    return phi_true, psi_true, theta_true, rewards, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc576cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the beta\n",
    "def get_beta(rho, delta, V_bar, theta_true):\n",
    "    \n",
    "    ld = 1\n",
    "    beta = rho * np.sqrt(2 * np.log((np.sqrt(np.linalg.det(V_bar)) * (np.linalg.det(ld * np.eye(d)) ** (-1/2))) / delta)) + np.sqrt(ld) * np.linalg.norm(theta_true)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slsqp\n",
    "def get_decision(psi_action, theta_hat, V_bar, beta, d):\n",
    "    \n",
    "    def maximize_reward(theta, psi_a):\n",
    "\n",
    "        return -1.0 * psi_a.dot(theta)\n",
    "    \n",
    "    # constraint confidence set: || theta_hat - theta ||_V_bar < Beta\n",
    "    def constraint(theta, theta_hat, V_bar, beta):\n",
    "        \n",
    "        temp = np.array(theta_hat - theta.reshape(-1, 1))\n",
    "        norm = np.sqrt(temp.reshape(-1, 1).T.dot(V_bar).dot(temp.reshape(-1, 1)))\n",
    "        \n",
    "        return beta - norm[0][0]\n",
    "    \n",
    "    # constraints for optimization\n",
    "    beta_constraint = {'type': 'ineq', 'fun' : lambda theta: constraint(theta, theta_hat, V_bar, beta)}\n",
    "    \n",
    "    theta_list = []\n",
    "    reward_list = []\n",
    "    \n",
    "    for psi_a in psi_action:\n",
    "        \n",
    "        res = minimize(maximize_reward, x0 = np.ones(d), args = (psi_a), method = 'SLSQP', constraints = [beta_constraint], options = {'ftol': 1e-3, 'eps': 1e-10, 'maxiter': 1e6, 'disp': False})\n",
    "        theta_list.append(res.x)\n",
    "        reward_list.append(psi_a.dot(res.x))\n",
    "        # print(res.message)\n",
    "        \n",
    "    decision = np.argmax(reward_list)\n",
    "    theta_tilde = theta_list[decision]\n",
    "    \n",
    "    return decision, theta_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_data(data_list, trials, iterations, num_agent, every_num_point):\n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    for T in range(trials):\n",
    "\n",
    "        new_list.append([item[1] for item in data_list if item[0] == T])\n",
    "\n",
    "    new_list = np.array(new_list).reshape(trials, iterations).tolist()\n",
    "    \n",
    "    data_value = np.zeros(iterations)\n",
    "    \n",
    "    for T in range(trials):\n",
    "        \n",
    "        data_value += np.array(new_list[T])\n",
    "        \n",
    "    data_value = data_value / trials\n",
    "    \n",
    "    x_value = [0]\n",
    "    y_value = [data_value[0] / num_agent[0]]\n",
    "    \n",
    "    for num in range(int(iterations / every_num_point)):\n",
    "        \n",
    "        x_value.append((num + 1) * every_num_point - 1)\n",
    "        y_value.append(data_value[(num + 1) * every_num_point - 1] / num_agent[0])\n",
    "    \n",
    "    return x_value, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "R = 1\n",
    "ld = 1\n",
    "trials = 100\n",
    "alpha = 0.01\n",
    "num_agent = [1]\n",
    "baseline_idx = 10\n",
    "delta_value = 1e-3\n",
    "iterations = 20000\n",
    "every_num_point = 25\n",
    "optimal_alg = []\n",
    "optimal_ECC = []\n",
    "optimal_sw = []\n",
    "optimal_sw_UCB = []\n",
    "reward_alg = []\n",
    "reward_ECC = []\n",
    "reward_sw = []\n",
    "reward_sw_UCB = []\n",
    "baseline_alg = []\n",
    "baseline_ECC = []\n",
    "baseline_sw = []\n",
    "baseline_sw_UCB = []\n",
    "cummulative_regret_alg = []\n",
    "cumulative_violate_alg = []\n",
    "cumulative_baseline_alg = []\n",
    "cummulative_regret_ECC = []\n",
    "cumulative_violate_ECC = []\n",
    "cumulative_baseline_ECC = []\n",
    "cummulative_regret_sw = []\n",
    "cumulative_violate_sw = []\n",
    "cumulative_baseline_sw = []\n",
    "cummulative_regret_sw_UCB = []\n",
    "cumulative_violate_sw_UCB = []\n",
    "cumulative_baseline_sw_UCB = []\n",
    "theta_true = np.array([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_true_group_T = []\n",
    "psi_true_group_T = []\n",
    "sample_id_T = []\n",
    "noise_T = []\n",
    "r_h_T = []\n",
    "r_l_T = []\n",
    "rho_bar_T = []\n",
    "zeta_T = []\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    phi_true, psi_true, theta_true, rewards, d = generate_data(int(1e2))\n",
    "    L = np.max(np.linalg.norm(phi_true, axis = 2))\n",
    "    \n",
    "    phi_true_1 = phi_true.copy()\n",
    "    phi_true_1[:, :, 1] = 0\n",
    "\n",
    "    phi_true_2 = phi_true.copy()\n",
    "    phi_true_2[:, :, 0] = 0\n",
    "    \n",
    "    psi_true_1 = psi_true.copy()\n",
    "    psi_true_1[:, :, 1] = 0\n",
    "\n",
    "    psi_true_2 = psi_true.copy()\n",
    "    psi_true_2[:, :, 0] = 0\n",
    "    \n",
    "    phi_true_group = np.array([phi_true, phi_true_1, phi_true_2] * 3)\n",
    "    psi_true_group = np.array([psi_true, psi_true_1, psi_true_2] * 3)\n",
    "    \n",
    "    # generate the index set for context\n",
    "    sample_id = np.random.randint(0, np.shape(phi_true)[0], size = iterations)\n",
    "\n",
    "    # generate the noise of reward for each iteration\n",
    "    noise = np.random.normal(0, 1e-3, size = (num_agent[-1], trials, iterations))\n",
    "\n",
    "    # calculate r_l and r_h\n",
    "    product_results = np.dot(phi_true_group, theta_true)\n",
    "    sorted_values = np.sort(product_results, axis=2)\n",
    "    all_baseline_values = sorted_values[:, :, -baseline_idx]\n",
    "    r_h = np.max(all_baseline_values)\n",
    "    r_l = np.min(all_baseline_values)\n",
    "\n",
    "    # gererate rho_bar\n",
    "    rho_bar = np.random.uniform(1e-10, np.min(alpha) * r_l / (np.linalg.norm(theta_true) + r_h), size = (trials, iterations))\n",
    "\n",
    "    # generate zeta\n",
    "    zeta_data = np.random.normal(0, 1e-3, (trials, iterations, len(theta_true)))\n",
    "    zeta_zero = zeta_data - np.mean(zeta_data, axis = 2, keepdims = True)\n",
    "    zeta = zeta_zero / np.linalg.norm(zeta_zero, axis = 2, keepdims = True)\n",
    "    \n",
    "    phi_true_group_T.append(phi_true_group)\n",
    "    psi_true_group_T.append(psi_true_group)\n",
    "    sample_id_T.append(sample_id)\n",
    "    noise_T.append(noise)\n",
    "    r_h_T.append(r_h)\n",
    "    r_l_T.append(r_l)\n",
    "    rho_bar_T.append(rho_bar)\n",
    "    zeta_T.append(zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445fb2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# our setting\n",
    "start = time.time()\n",
    "\n",
    "for M in num_agent:\n",
    "    \n",
    "    for T in range(trials):\n",
    "        \n",
    "        phi_true_group = phi_true_group_T[T]\n",
    "        psi_true_group = psi_true_group_T[T]\n",
    "        sample_id = sample_id_T[T]\n",
    "        noise = noise_T[T]\n",
    "        r_h = r_h_T[T]\n",
    "        r_l = r_l_T[T]\n",
    "        rho_bar = rho_bar_T[T]\n",
    "        zeta = zeta_T[T]\n",
    "        L = np.max(np.linalg.norm(phi_true_group[0], axis = 2))\n",
    "        \n",
    "        total_regret = 0\n",
    "        total_reward = 0\n",
    "        total_violate = 0\n",
    "        total_baseline = 0\n",
    "        cummulative_regret = []\n",
    "        cummulative_violate = []\n",
    "        cummulative_baseline = []\n",
    "        optimal_list = []\n",
    "        reward_list = []\n",
    "        baseline_list = []\n",
    "        \n",
    "        t_last = 0\n",
    "        V_last = ld * np.eye(d)\n",
    "        W_syn = np.zeros((d, d))\n",
    "        U_syn = np.zeros((d, 1))\n",
    "        \n",
    "        W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "        U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "        \n",
    "        B = (iterations * np.log(M * iterations)) / (d * M)\n",
    "        print('B is equal to', B)\n",
    "        \n",
    "        syn = 0\n",
    "\n",
    "        for t in range(1, iterations + 1): \n",
    "            \n",
    "            print('')\n",
    "            print('Trial: {} t: {}:'.format(T,t))\n",
    "            \n",
    "            index = sample_id[t-1]\n",
    "            \n",
    "            for i in range(M):\n",
    "                \n",
    "                phi = phi_true_group[i][index]\n",
    "                psi = psi_true_group[i][index]\n",
    "\n",
    "                x_star = np.argmax(np.dot(np.array(psi), theta_true))\n",
    "                optimal = np.dot(np.array(phi[x_star]), theta_true)\n",
    "                print('best decision is:', np.argmax(np.dot(phi, theta_true)))\n",
    "\n",
    "                x_b = np.argsort(phi.dot(theta_true))[::-1][baseline_idx]\n",
    "                r_b = phi[x_b].dot(theta_true)\n",
    "                print('baseline decision is:', x_b)\n",
    "                \n",
    "                V_bar = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                theta_hat = np.dot(np.linalg.inv(V_bar), (U_syn + U_new_list[i]))\n",
    "\n",
    "                # construct the confidence ellipsoid beta\n",
    "                beta = get_beta(rho = np.sqrt(1 + R ** 2), delta = delta_value / 2, V_bar = V_bar, theta_true = theta_true)\n",
    "                \n",
    "                #construct the trimmed action set\n",
    "                tas = (psi.dot(theta_hat) >= beta * L / np.sqrt(np.min(np.linalg.eigvals(V_bar))) + (1 - alpha) * r_b)\n",
    "                phi_set = phi[tas.ravel()]\n",
    "                psi_set = psi[tas.ravel()]\n",
    "                \n",
    "                # get the best action\n",
    "                if (psi_set.size != 0) and (np.min(np.linalg.eigvals(V_bar)) >= np.square(2 * L * beta / ((optimal - r_h) + alpha * r_b))):\n",
    "                \n",
    "                    decision, theta_tilde = get_decision(psi_set, theta_hat, V_bar, beta, d)\n",
    "                    psi_new = psi_set[decision]\n",
    "                    y = np.dot(phi_set[decision], theta_true)\n",
    "                    print(\"play learner's decision:\", decision)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    decision = x_b\n",
    "                    total_baseline += 1\n",
    "                    psi_new = (1 - rho_bar[T][t-1]) * psi[decision] + rho_bar[T][t-1] * zeta[T][t-1]\n",
    "                    y = (1 - rho_bar[T][t-1]) * np.dot(phi[decision], theta_true) + rho_bar[T][t-1] * np.dot(zeta[T][t-1], theta_true)\n",
    "                    print(\"play conservative decision:\", decision)\n",
    "                    \n",
    "                regret = optimal - y\n",
    "                total_regret = total_regret + regret\n",
    "                total_reward = total_reward + y\n",
    "\n",
    "                # update W_new and U_new\n",
    "                W_new_list[i] = W_new_list[i] + np.outer(psi_new, psi_new)\n",
    "                U_new_list[i] = U_new_list[i] + psi_new.reshape(-1, 1) * (y + noise[i][T][t-1])\n",
    "                V = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                \n",
    "                LHS_condition = np.log(np.linalg.det(V) / np.linalg.det(V_last)) * (t - t_last)\n",
    "                \n",
    "                if LHS_condition >= B:\n",
    "                    \n",
    "                    print('synchronization start for agent', i)\n",
    "                    print('LHS condition is:', LHS_condition)\n",
    "                    \n",
    "                    syn = 1\n",
    "                    \n",
    "                print('----------')\n",
    "                \n",
    "                if y < (1 - alpha) * r_b:\n",
    "                    \n",
    "                    total_violate += 1\n",
    "                    print('violate the constraint1111111111111111111111111111111111111')\n",
    "                    \n",
    "            if syn == 1:\n",
    "                \n",
    "                W_syn = W_syn + np.sum(W_new_list, axis=0)\n",
    "                U_syn = U_syn + np.sum(U_new_list, axis=0)\n",
    "                \n",
    "                W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "                U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "                t_last = t\n",
    "                V_last = ld * np.eye(d) + W_syn\n",
    "                \n",
    "                syn = 0\n",
    "                \n",
    "            print('cummulative_regret is: ', total_regret)\n",
    "            cummulative_regret.append(total_regret)\n",
    "            cummulative_violate.append(total_violate)\n",
    "            cummulative_baseline.append(total_baseline)\n",
    "            optimal_list.append(np.max(np.dot(phi, theta_true)))\n",
    "            reward_list.append(y)\n",
    "            baseline_list.append((1 - alpha) * r_b)\n",
    "            \n",
    "        cummulative_regret_alg.append((T, cummulative_regret))\n",
    "        cumulative_violate_alg.append((T, cummulative_violate))\n",
    "        cumulative_baseline_alg.append((T, cummulative_baseline))\n",
    "        optimal_alg.append((T, optimal_list))\n",
    "        reward_alg.append((T, reward_list))\n",
    "        baseline_alg.append((T, baseline_list))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECC setting\n",
    "start = time.time()\n",
    "\n",
    "for M in num_agent:\n",
    "    \n",
    "    for T in range(trials):\n",
    "        \n",
    "        phi_true_group = phi_true_group_T[T]\n",
    "        psi_true_group = psi_true_group_T[T]\n",
    "        sample_id = sample_id_T[T]\n",
    "        noise = noise_T[T]\n",
    "        r_h = r_h_T[T]\n",
    "        r_l = r_l_T[T]\n",
    "        rho_bar = rho_bar_T[T]\n",
    "        zeta = zeta_T[T]\n",
    "        L = np.max(np.linalg.norm(phi_true_group[0], axis = 2))\n",
    "        \n",
    "        total_regret = 0\n",
    "        total_reward = 0\n",
    "        total_violate = 0\n",
    "        total_baseline = 0\n",
    "        cummulative_regret = []\n",
    "        cummulative_violate = []\n",
    "        cummulative_baseline = []\n",
    "        optimal_list = []\n",
    "        reward_list = []\n",
    "        baseline_list = []\n",
    "        \n",
    "        t_last = 0\n",
    "        V_last = ld * np.eye(d)\n",
    "        W_syn = np.zeros((d, d))\n",
    "        U_syn = np.zeros((d, 1))\n",
    "        \n",
    "        W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "        U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "        \n",
    "        B = (iterations * np.log(M * iterations)) / (d * M)\n",
    "        print('B is equal to', B)\n",
    "        \n",
    "        syn = 0\n",
    "\n",
    "        for t in range(1, iterations + 1): \n",
    "            \n",
    "            print('')\n",
    "            print('Trial: {} t: {}:'.format(T,t))\n",
    "            \n",
    "            index = sample_id[t-1]\n",
    "            \n",
    "            for i in range(M):\n",
    "                \n",
    "                phi = phi_true_group[i][index]\n",
    "                psi = psi_true_group[i][index]\n",
    "\n",
    "                x_star = np.argmax(np.dot(np.array(psi), theta_true))\n",
    "                optimal = np.dot(np.array(phi[x_star]), theta_true)\n",
    "                print('best decision is:', np.argmax(np.dot(phi, theta_true)))\n",
    "\n",
    "                x_b = np.argsort(phi.dot(theta_true))[::-1][baseline_idx]\n",
    "                r_b = phi[x_b].dot(theta_true)\n",
    "                print('baseline decision is:', x_b)\n",
    "\n",
    "                V_bar = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                theta_hat = np.dot(np.linalg.inv(V_bar), (U_syn + U_new_list[i]))\n",
    "\n",
    "                # construct the confidence ellipsoid beta\n",
    "                beta = get_beta(rho = np.sqrt(1 + R ** 2), delta = delta_value / 2, V_bar = V_bar, theta_true = theta_true)\n",
    "                \n",
    "                # get the best combination of action and theta_tilde\n",
    "                decision, theta_tilde = get_decision(psi, theta_hat, V_bar, beta, d)\n",
    "                print('Decision:', decision)\n",
    "                \n",
    "                y = np.dot(phi[decision], theta_true)\n",
    "                regret = optimal - y\n",
    "                total_regret = total_regret + regret\n",
    "                total_reward = total_reward + y\n",
    "\n",
    "                # update W_new and U_new\n",
    "                W_new_list[i] = W_new_list[i] + np.outer(psi[decision], psi[decision])\n",
    "                U_new_list[i] = U_new_list[i] + psi[decision].reshape(-1, 1) * (y + noise[i][T][t-1])\n",
    "                V = ld * np.eye(d) + W_syn + W_new_list[i]\n",
    "                \n",
    "                LHS_condition = np.log(np.linalg.det(V) / np.linalg.det(V_last)) * (t - t_last)\n",
    "                \n",
    "                if LHS_condition >= B:\n",
    "                    \n",
    "                    print('synchronization start for agent', i)\n",
    "                    print('LHS condition is:', LHS_condition)\n",
    "                    \n",
    "                    syn = 1\n",
    "                    \n",
    "                print('----------')\n",
    "                \n",
    "                if y < (1 - alpha) * r_b:\n",
    "                    \n",
    "                    total_violate += 1\n",
    "                    print('violate the constraint')\n",
    "                \n",
    "            if syn == 1:\n",
    "                \n",
    "                W_syn = W_syn + np.sum(W_new_list, axis=0)\n",
    "                U_syn = U_syn + np.sum(U_new_list, axis=0)\n",
    "                \n",
    "                W_new_list = [np.zeros((d, d)) for i in range(M)]\n",
    "                U_new_list = [np.zeros((d, 1)) for i in range(M)]\n",
    "                t_last = t\n",
    "                V_last = ld * np.eye(d) + W_syn\n",
    "                \n",
    "                syn = 0\n",
    "                    \n",
    "            print('cummulative_regret is: ', total_regret)\n",
    "            cummulative_regret.append(total_regret)\n",
    "            cummulative_violate.append(total_violate)\n",
    "            cummulative_baseline.append(total_baseline)\n",
    "            optimal_list.append(np.max(np.dot(phi, theta_true)))\n",
    "            reward_list.append(y)\n",
    "            baseline_list.append((1 - alpha) * r_b)\n",
    "            \n",
    "        cummulative_regret_ECC.append((T, cummulative_regret))\n",
    "        cumulative_violate_ECC.append((T, cummulative_violate))\n",
    "        cumulative_baseline_ECC.append((T, cummulative_baseline))\n",
    "        optimal_ECC.append((T, optimal_list))\n",
    "        reward_ECC.append((T, reward_list))\n",
    "        baseline_ECC.append((T, baseline_list))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99754b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage-wise TS setting\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "        \n",
    "    phi_true_group = phi_true_group_T[T]\n",
    "    psi_true_group = psi_true_group_T[T]\n",
    "    sample_id = sample_id_T[T]\n",
    "    noise = noise_T[T]\n",
    "    r_h = r_h_T[T]\n",
    "    r_l = r_l_T[T]\n",
    "    rho_bar = rho_bar_T[T]\n",
    "    zeta = zeta_T[T]\n",
    "    L = np.max(np.linalg.norm(phi_true_group[0], axis = 2))\n",
    "        \n",
    "    total_regret = 0\n",
    "    total_reward = 0\n",
    "    total_violate = 0\n",
    "    total_baseline = 0\n",
    "    cummulative_regret = []\n",
    "    cummulative_violate = []\n",
    "    cummulative_baseline = []\n",
    "    optimal_list = []\n",
    "    reward_list = []\n",
    "    baseline_list = []\n",
    "    \n",
    "    delta_ = delta_value / (10 * iterations)\n",
    "    \n",
    "    W = np.zeros((d, d))\n",
    "    U = np.zeros((d, 1))\n",
    "\n",
    "    for t in range(1, iterations + 1): \n",
    "\n",
    "        print('')\n",
    "        print('Trial: {} t: {}:'.format(T,t))\n",
    "        \n",
    "        index = sample_id[t-1]\n",
    "        phi = phi_true_group[0][index]\n",
    "        psi = psi_true_group[0][index]\n",
    "\n",
    "        x_star = np.argmax(np.dot(np.array(psi), theta_true))\n",
    "        optimal = np.dot(np.array(phi[x_star]), theta_true)\n",
    "        print('best decision is:', np.argmax(np.dot(phi, theta_true)))\n",
    "\n",
    "        x_b = np.argsort(phi.dot(theta_true))[::-1][baseline_idx]\n",
    "        r_b = phi[x_b].dot(theta_true)\n",
    "        print('baseline decision is:', x_b)\n",
    "        \n",
    "        # sample eta\n",
    "        eta = np.random.multivariate_normal(mean = np.zeros(d), cov = np.eye(d))\n",
    "        \n",
    "        # compute RLS-estimate theta_hat and V\n",
    "        V = ld * np.eye(d) + W\n",
    "        theta_hat = np.dot(np.linalg.inv(V), U)\n",
    "        \n",
    "        # compute the beta\n",
    "        beta = R * np.sqrt(d * np.log((1 + t * L ** 2 / ld) / delta_)) + np.sqrt(ld) * np.linalg.norm(theta_true)\n",
    "        \n",
    "        # calculate V^{-1/2}\n",
    "        eigvals, eigvecs = np.linalg.eigh(V)\n",
    "        temp = eigvecs.dot(np.diag(1.0 / np.sqrt(eigvals))).dot(eigvecs.T)\n",
    "        \n",
    "        # compute theta_tilde\n",
    "        theta_tilde = theta_hat + beta * (temp.dot(eta)).reshape(-1, 1)\n",
    "        \n",
    "        # compute the estimated safe set Xi\n",
    "        Xi = (psi.dot(theta_hat) - (beta * np.array([np.sqrt(psi[i].dot(np.linalg.inv(V)).dot(psi[i].T)) for i in range(psi.shape[0])]).reshape(-1, 1)) >= (1 - alpha) * r_b)\n",
    "        phi_set = phi[Xi.ravel()]\n",
    "        psi_set = psi[Xi.ravel()]\n",
    "        \n",
    "        # get the best action\n",
    "        if (psi_set.size != 0) and (np.min(np.linalg.eigvals(V)) >= np.square(2 * L * beta / ((optimal - r_h) + alpha * r_b))):\n",
    "\n",
    "            decision = np.argmax(psi_set.dot(theta_tilde))\n",
    "            psi_new = psi_set[decision]\n",
    "            y = np.dot(phi_set[decision], theta_true)\n",
    "            print(\"play learner's decision:\", decision)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            decision = x_b\n",
    "            total_baseline += 1\n",
    "            psi_new = (1 - rho_bar[T][t-1]) * psi[decision] + rho_bar[T][t-1] * zeta[T][t-1]\n",
    "            y = (1 - rho_bar[T][t-1]) * np.dot(phi[decision], theta_true) + rho_bar[T][t-1] * np.dot(zeta[T][t-1], theta_true)\n",
    "            print(\"play conservative decision:\", decision)\n",
    "            \n",
    "        regret = optimal - y\n",
    "        total_regret = total_regret + regret\n",
    "        total_reward = total_reward + y\n",
    "        \n",
    "        W += np.outer(psi_new, psi_new)\n",
    "        U += psi_new.reshape(-1, 1) * (y + noise[0][T][t-1])\n",
    "                \n",
    "        if y < (1 - alpha) * r_b:\n",
    "\n",
    "            total_violate += 1\n",
    "            print('violate the constraint')\n",
    "        \n",
    "        print('cummulative_regret is: ', total_regret)\n",
    "        cummulative_regret.append(total_regret)\n",
    "        cummulative_violate.append(total_violate)\n",
    "        cummulative_baseline.append(total_baseline)\n",
    "        optimal_list.append(np.max(np.dot(phi, theta_true)))\n",
    "        reward_list.append(y)\n",
    "        baseline_list.append((1 - alpha) * r_b)\n",
    "        \n",
    "    cummulative_regret_sw.append((T, cummulative_regret))\n",
    "    cumulative_violate_sw.append((T, cummulative_violate))\n",
    "    cumulative_baseline_sw.append((T, cummulative_baseline))\n",
    "    optimal_sw.append((T, optimal_list))\n",
    "    reward_sw.append((T, reward_list))\n",
    "    baseline_sw.append((T, baseline_list))\n",
    "    \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value, y_alg = prepare_plot_data(cummulative_regret_alg, trials, iterations, num_agent, every_num_point)\n",
    "x_value_r, y_optimal_alg = prepare_plot_data(optimal_alg, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_reward_alg = prepare_plot_data(reward_alg, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_baseline_alg = prepare_plot_data(baseline_alg, trials, iterations, num_agent, 1)\n",
    "\n",
    "x_value, y_ECC = prepare_plot_data(cummulative_regret_ECC, trials, iterations, num_agent, every_num_point)\n",
    "x_value_r, y_optimal_ECC = prepare_plot_data(optimal_ECC, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_reward_ECC = prepare_plot_data(reward_ECC, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_baseline_ECC = prepare_plot_data(baseline_ECC, trials, iterations, num_agent, 1)\n",
    "\n",
    "x_value, y_sw = prepare_plot_data(cummulative_regret_sw, trials, iterations, num_agent, every_num_point)\n",
    "x_value_r, y_optimal_sw = prepare_plot_data(optimal_sw, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_reward_sw = prepare_plot_data(reward_sw, trials, iterations, num_agent, 1)\n",
    "x_value_r, y_baseline_sw = prepare_plot_data(baseline_sw, trials, iterations, num_agent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "\n",
    "colors = (['black', 'blue', 'darkgreen', 'purple', 'darkred', 'grey'])\n",
    "markers = ['*', 's', 'o', 'X', '^', 'P']\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 25\n",
    "plt.rcParams['ytick.labelsize'] = 25\n",
    "plt.rc('legend', fontsize = 25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='both', scilimits=(0, 0), useOffset=False)\n",
    "\n",
    "plt.plot(x_value, y_alg, label = 'Algorithm', color = colors[1], linewidth=3)\n",
    "plt.scatter(x_value[::100], y_alg[::100], label = 'Algorithm', marker = markers[1], color = colors[1], s=300)\n",
    "plt.plot(x_value, y_ECC, label = 'ECC', color = colors[2], linewidth=3)\n",
    "plt.scatter(x_value[::100], y_ECC[::100], label = 'ECC', marker = markers[2], color = colors[2], s=300)\n",
    "plt.plot(x_value, y_sw, label = 'Stage-Wise-TS', color = colors[3], linewidth=3)\n",
    "plt.scatter(x_value[::100], y_sw[::100], label = 'Stage-Wise-TS', marker = markers[3], color = colors[3], s=300)\n",
    "\n",
    "legend_elements = [mlines.Line2D([0], [0], color=colors[1], lw = 5, label = 'DiSC-UCB', marker = markers[1], markersize = 15),\n",
    "                   mlines.Line2D([0], [0], color=colors[2], lw = 5, label = 'DisLinUCB', marker = markers[2], markersize = 15),\n",
    "                   mlines.Line2D([0], [0], color=colors[3], lw = 5, label = 'SCLTS', marker = markers[3], markersize = 15)]\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('round,t', fontsize=25)\n",
    "plt.ylabel('cumulative regret Rt', fontsize=25)\n",
    "plt.title('synthetic data', fontsize=25)\n",
    "plt.legend(handles=legend_elements)\n",
    "# plt.savefig('plot_1.pdf', dpi=600, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "plt.figure(figsize=(12,8), dpi=300)\n",
    "\n",
    "colors = (['black', 'blue', 'darkgreen', 'purple', 'darkred', 'grey'])\n",
    "markers = ['*', 's', 'o', 'X', '^', 'P']\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 25\n",
    "plt.rcParams['ytick.labelsize'] = 25\n",
    "plt.rc('legend', fontsize = 25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='both', scilimits=(0, 0), useOffset=False)\n",
    "\n",
    "plt.plot(x_value_r[::100], y_optimal_alg[::100], label = 'Optimal-Reward', linestyle = '--', color = colors[0], linewidth=3)\n",
    "plt.plot(x_value_r, y_reward_alg, label = 'DiSC-UCB', color = colors[1], linewidth=3)\n",
    "plt.plot(x_value_r[::100], y_baseline_sw[::100], label = 'Conservative-Reward', linestyle = '--', color = colors[5], linewidth=3)\n",
    "\n",
    "plt.ylim(0.5, 1.1)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('round,t', fontsize=25)\n",
    "plt.ylabel('reward,r', fontsize=25)\n",
    "plt.title('synthetic data', fontsize=25)\n",
    "plt.legend()\n",
    "# plt.savefig('plot_2.pdf', dpi=600, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_plot(data):\n",
    "    \n",
    "    list_T = []\n",
    "    list_vio = [0]\n",
    "    \n",
    "    for T in range(trials):\n",
    "\n",
    "        list_temp = [0]\n",
    "        \n",
    "        for i in range(1, len(data[T][1])):\n",
    "            \n",
    "            if data[T][1][i] != data[T][1][i-1]:\n",
    "\n",
    "                list_temp.append(list_temp[-1] + 1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                list_temp.append(list_temp[-1])\n",
    "\n",
    "        list_T.append(list_temp)\n",
    "        \n",
    "    for i in range(1, len(list_T[0])):\n",
    "        \n",
    "        if any(sublist[i] != 0 for sublist in list_T):\n",
    "            \n",
    "            list_vio.append(list_vio[-1] + 1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            list_vio.append(list_vio[-1])\n",
    "            \n",
    "    return list_vio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value_r = [i for i in range(iterations)]\n",
    "num_violation_alg = preprocessing_plot(cumulative_violate_alg)\n",
    "num_violation_ECC = preprocessing_plot(ECC_violation)\n",
    "num_violation_sw = preprocessing_plot(cumulative_violate_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "plt.figure(figsize=(12,8), dpi=300)\n",
    "\n",
    "colors = (['black', 'blue', 'darkgreen', 'purple', 'darkred', 'grey'])\n",
    "markers = ['*', 's', 'o', 'X', '^', 'P']\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 25\n",
    "plt.rcParams['ytick.labelsize'] = 25\n",
    "plt.rc('legend', fontsize = 25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='both', scilimits=(0, 0), useOffset=False)\n",
    "\n",
    "plt.plot(x_value_r, num_violation_alg, label = 'DiSC-UCB', color = colors[1], linewidth = 3, linestyle = '-')\n",
    "plt.plot(x_value_r, num_violation_ECC, label = 'DisLinUCB', color = colors[2], linewidth = 3, linestyle = '--')\n",
    "plt.plot(x_value_r, num_violation_sw, label = 'SCLTS', color = colors[3], linewidth = 3, linestyle = '-.')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('round,t', fontsize=25)\n",
    "plt.ylabel('cumulative violation', fontsize=25)\n",
    "plt.title('synthetic data', fontsize=25)\n",
    "plt.legend()\n",
    "# plt.savefig('plot_3.pdf', dpi=600, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76298876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
